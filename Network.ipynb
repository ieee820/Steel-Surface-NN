{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, cv2, os, shutil, random, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programs\\Anaconda3\\envs\\ai\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras, h5py\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuClassificationSurfaceDefects:\n",
    "    source_data_dir = 'sources/NEU-CLS'\n",
    "    formatted_data = 'neu-data'\n",
    "    \n",
    "    train_dir = os.path.join(formatted_data, 'train')\n",
    "    val_dir = os.path.join(formatted_data, 'val')\n",
    "    test_dir = os.path.join(formatted_data, 'test')\n",
    "    \n",
    "    test_data_portion = 0.15\n",
    "    val_data_portion = 0.15\n",
    "    \n",
    "    classes = ['rolled-in scale', 'patches', 'crazing', 'pitted surface', 'inclusion', 'scratches']\n",
    "    short_classes = ['RS', 'Pa', 'Cr','PS', 'In', 'Sc']\n",
    "    nb_images = 300\n",
    "    \n",
    "    img_width, img_height = 200, 200\n",
    "    \n",
    "    input_shape = (img_width, img_height, 3)\n",
    "    total_classes = len(classes)\n",
    "    \n",
    "    nb_train_samples = 1254\n",
    "    nb_validation_samples = 270    \n",
    "    nb_test_samples = 276\n",
    "    \n",
    "    @classmethod\n",
    "    def get_generators(cls, batch_size, use_samplewise=True):\n",
    "        datagen = ImageDataGenerator(\n",
    "            samplewise_center=use_samplewise, \n",
    "            samplewise_std_normalization=use_samplewise,\n",
    "            featurewise_center=not use_samplewise,\n",
    "            featurewise_std_normalization=not use_samplewise,\n",
    "            rotation_range=40,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            rescale=1. / 255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest')\n",
    "        train_generator = datagen.flow_from_directory(\n",
    "            cls.train_dir,\n",
    "            target_size=(cls.img_width, cls.img_height),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "        val_generator = datagen.flow_from_directory(\n",
    "            cls.val_dir,\n",
    "            target_size=(cls.img_width, cls.img_height),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "        test_generator = datagen.flow_from_directory(\n",
    "            cls.test_dir,\n",
    "            target_size=(cls.img_width, cls.img_height),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "        return train_generator, val_generator, test_generator\n",
    "    \n",
    "    @classmethod\n",
    "    def prepare_data(cls):\n",
    "        \n",
    "        def create_directory(dir_name):\n",
    "            if os.path.exists(dir_name):\n",
    "                shutil.rmtree(dir_name)\n",
    "            os.makedirs(dir_name)\n",
    "            for c in cls.classes: \n",
    "                os.makedirs(os.path.join(dir_name, c))\n",
    "            print('Directory \"' + dir_name + '\" was created.')\n",
    "        \n",
    "        create_directory(cls.train_dir)\n",
    "        create_directory(cls.val_dir)\n",
    "        create_directory(cls.test_dir)\n",
    "    \n",
    "        def copy_images(start_index, end_index, source_dir, dest_dir):\n",
    "            for i in range(start_index, end_index):\n",
    "                for j in range(len(cls.classes)):\n",
    "                    shutil.copy2(os.path.join(source_dir, cls.short_classes[j] + \"_\" + str(i) + \".bmp\"), \n",
    "                                 os.path.join(dest_dir, cls.classes[j]))\n",
    "                    \n",
    "        start_val_data_idx = int(cls.nb_images * (1 - cls.val_data_portion - cls.test_data_portion))\n",
    "        start_test_data_idx = int(cls.nb_images * (1 - cls.test_data_portion))\n",
    "        print(\"Train[{}, {}], Val[{}, {}], Test[{}, {}]\".format(1, start_val_data_idx - 1, start_val_data_idx, start_test_data_idx - 1, start_test_data_idx, cls.nb_images ))\n",
    "        copy_images(1, start_val_data_idx, cls.source_data_dir, cls.train_dir)\n",
    "        print(\"Train data prepared\")\n",
    "        copy_images(start_val_data_idx, start_test_data_idx, cls.source_data_dir, cls.val_dir)\n",
    "        print(\"Val data prepared\")\n",
    "        copy_images(start_test_data_idx, cls.nb_images + 1, cls.source_data_dir, cls.test_dir)\n",
    "        print(\"Test data prepared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускать при изменении параметров в `NeuClassificationSurfaceDefects`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NeuClassificationSurfaceDefects.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = 'Network-{}'.format(''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(10)))\n",
    "model_dir = os.path.join('models', network_name)\n",
    "model_file_path = os.path.join(model_dir, '{}.model'.format(network_name))\n",
    "os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Основные параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 1000\n",
    "steps_per_epoch = NeuClassificationSurfaceDefects.nb_train_samples // batch_size\n",
    "validation_steps = NeuClassificationSurfaceDefects.nb_validation_samples // batch_size\n",
    "input_shape = NeuClassificationSurfaceDefects.input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При передаче параметра `use_samplewise=False`, будет использована featurewise-нормализация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1254 images belonging to 6 classes.\n",
      "Found 270 images belonging to 6 classes.\n",
      "Found 276 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, val_generator, test_generator = NeuClassificationSurfaceDefects.get_generators(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_point = keras.callbacks.ModelCheckpoint(model_file_path, \n",
    "                                              monitor='val_acc', verbose=1,\n",
    "                                              save_best_only=True,\n",
    "                                              save_weights_only=False,\n",
    "                                              mode='auto', \n",
    "                                              period=1)\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', \n",
    "                                               min_delta=0, \n",
    "                                               patience=10, \n",
    "                                               verbose=1, \n",
    "                                               mode='auto')\n",
    "tb_callback = TensorBoard(log_dir=os.path.join(model_dir,'Graph'),\n",
    "                          histogram_freq=0,\n",
    "                          write_graph=True,\n",
    "                          write_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Архитектура сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), input_shape=input_shape, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 200, 200, 128)     3584      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 200, 200, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 100, 100, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 100, 100, 32)      36896     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 50, 50, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 25, 25, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                294976    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 465,126\n",
      "Trainable params: 465,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "summary = model.summary()\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=validation_steps,\n",
    "        verbose=1, \n",
    "        callbacks=[check_point, \n",
    "                   early_stopping, \n",
    "                   tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(model_file_path)\n",
    "scores = model.evaluate_generator(test_generator, NeuClassificationSurfaceDefects.nb_test_samples // batch_size)\n",
    "acc = scores[1]*100\n",
    "print(\"Точность на тестовых данных: %.2f%%\" % (acc))\n",
    "print(\"Точность на тестовых данных: {}\\n{}\".format(acc, summary), file=open(os.path.join(model_dir, 'README.md'.format(network_name)), \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
