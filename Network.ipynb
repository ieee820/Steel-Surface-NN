{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, cv2, os, shutil, random, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras, h5py\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuClassificationSurfaceDefects:\n",
    "    source_data_dir = 'sources/NEU-CLS'\n",
    "    formatted_data = 'neu-data'\n",
    "    \n",
    "    train_dir = os.path.join(formatted_data, 'train')\n",
    "    val_dir = os.path.join(formatted_data, 'val')\n",
    "    test_dir = os.path.join(formatted_data, 'test')\n",
    "    \n",
    "    test_data_portion = 0.15\n",
    "    val_data_portion = 0.15\n",
    "    \n",
    "    classes = ['rolled-in scale', 'patches', 'crazing', 'pitted surface', 'inclusion', 'scratches']\n",
    "    short_classes = ['RS', 'Pa', 'Cr','PS', 'In', 'Sc']\n",
    "    nb_images = 300\n",
    "    \n",
    "    img_width, img_height = 200, 200\n",
    "    \n",
    "    input_shape = (img_width, img_height, 3)\n",
    "    total_classes = len(classes)\n",
    "    \n",
    "    nb_train_samples = 1254\n",
    "    nb_validation_samples = 270    \n",
    "    nb_test_samples = 276\n",
    "    \n",
    "    @classmethod\n",
    "    def get_generators(cls, batch_size, use_samplewise=True):\n",
    "        datagen = ImageDataGenerator(\n",
    "            samplewise_center=use_samplewise, \n",
    "            samplewise_std_normalization=use_samplewise,\n",
    "            featurewise_center=not use_samplewise,\n",
    "            featurewise_std_normalization=not use_samplewise,\n",
    "            rotation_range=40,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            rescale=1. / 255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest')\n",
    "        train_generator = datagen.flow_from_directory(\n",
    "            cls.train_dir,\n",
    "            target_size=(cls.img_width, cls.img_height),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "        val_generator = datagen.flow_from_directory(\n",
    "            cls.val_dir,\n",
    "            target_size=(cls.img_width, cls.img_height),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "        test_generator = datagen.flow_from_directory(\n",
    "            cls.test_dir,\n",
    "            target_size=(cls.img_width, cls.img_height),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "        return train_generator, val_generator, test_generator\n",
    "    \n",
    "    @classmethod\n",
    "    def prepare_data(cls):\n",
    "        \n",
    "        def create_directory(dir_name):\n",
    "            if os.path.exists(dir_name):\n",
    "                shutil.rmtree(dir_name)\n",
    "            os.makedirs(dir_name)\n",
    "            for c in cls.classes: \n",
    "                os.makedirs(os.path.join(dir_name, c))\n",
    "            print('Directory \"' + dir_name + '\" was created.')\n",
    "        \n",
    "        create_directory(cls.train_dir)\n",
    "        create_directory(cls.val_dir)\n",
    "        create_directory(cls.test_dir)\n",
    "    \n",
    "        def copy_images(start_index, end_index, source_dir, dest_dir):\n",
    "            for i in range(start_index, end_index):\n",
    "                for j in range(len(cls.classes)):\n",
    "                    shutil.copy2(os.path.join(source_dir, cls.short_classes[j] + \"_\" + str(i) + \".bmp\"), \n",
    "                                 os.path.join(dest_dir, cls.classes[j]))\n",
    "                    \n",
    "        start_val_data_idx = int(cls.nb_images * (1 - cls.val_data_portion - cls.test_data_portion))\n",
    "        start_test_data_idx = int(cls.nb_images * (1 - cls.test_data_portion))\n",
    "        print(\"Train[{}, {}], Val[{}, {}], Test[{}, {}]\".format(1, start_val_data_idx - 1, start_val_data_idx, start_test_data_idx - 1, start_test_data_idx, cls.nb_images ))\n",
    "        copy_images(1, start_val_data_idx, cls.source_data_dir, cls.train_dir)\n",
    "        print(\"Train data prepared\")\n",
    "        copy_images(start_val_data_idx, start_test_data_idx, cls.source_data_dir, cls.val_dir)\n",
    "        print(\"Val data prepared\")\n",
    "        copy_images(start_test_data_idx, cls.nb_images + 1, cls.source_data_dir, cls.test_dir)\n",
    "        print(\"Test data prepared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускать при изменении параметров в `NeuClassificationSurfaceDefects`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NeuClassificationSurfaceDefects.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = 'Network-{}'.format(''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(10)))\n",
    "model_dir = os.path.join('models', network_name)\n",
    "model_file_path = os.path.join(model_dir, '{}.model'.format(network_name))\n",
    "os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Основные параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 1000\n",
    "steps_per_epoch = NeuClassificationSurfaceDefects.nb_train_samples // batch_size\n",
    "validation_steps = NeuClassificationSurfaceDefects.nb_validation_samples // batch_size\n",
    "input_shape = NeuClassificationSurfaceDefects.input_shape\n",
    "\n",
    "base_learning_rate = 0.001\n",
    "learning_rate_factor = 0.5\n",
    "min_learning_rate = 0.00001\n",
    "learning_rate_patience = 5\n",
    "early_stopping_patience = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При передаче параметра `use_samplewise=False`, будет использована featurewise-нормализация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1254 images belonging to 6 classes.\n",
      "Found 270 images belonging to 6 classes.\n",
      "Found 276 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, val_generator, test_generator = NeuClassificationSurfaceDefects.get_generators(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_point = keras.callbacks.ModelCheckpoint(model_file_path, \n",
    "                                              monitor='val_acc', verbose=1,\n",
    "                                              save_best_only=True,\n",
    "                                              save_weights_only=False,\n",
    "                                              mode='auto', \n",
    "                                              period=1)\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', \n",
    "                                               min_delta=0, \n",
    "                                               patience=early_stopping_patience, \n",
    "                                               verbose=1, \n",
    "                                               mode='auto')\n",
    "tb_callback = TensorBoard(log_dir=os.path.join(model_dir,'Graph'),\n",
    "                          histogram_freq=0,\n",
    "                          write_graph=True,\n",
    "                          write_images=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', \n",
    "                              factor=learning_rate_factor,\n",
    "                              patience=learning_rate_patience, \n",
    "                              min_lr=min_learning_rate,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Архитектура сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), input_shape=input_shape, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(lr=base_learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 200, 200, 128)     3584      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 200, 200, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 100, 100, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 100, 100, 32)      36896     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 50, 50, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 25, 25, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                294976    \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6)                 390       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 465,126\n",
      "Trainable params: 465,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "156/156 [==============================] - 12s 76ms/step - loss: 1.6817 - acc: 0.2324 - val_loss: 1.4494 - val_acc: 0.3333\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.33333, saving model to models\\Network-3XLVPH2095\\Network-3XLVPH2095.model\n",
      "Epoch 2/1000\n",
      "156/156 [==============================] - 11s 72ms/step - loss: 1.4090 - acc: 0.3827 - val_loss: 1.2277 - val_acc: 0.4356\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.33333 to 0.43561, saving model to models\\Network-3XLVPH2095\\Network-3XLVPH2095.model\n",
      "Epoch 3/1000\n",
      "156/156 [==============================] - 11s 71ms/step - loss: 1.2113 - acc: 0.4888 - val_loss: 1.0906 - val_acc: 0.5189\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.43561 to 0.51894, saving model to models\\Network-3XLVPH2095\\Network-3XLVPH2095.model\n",
      "Epoch 4/1000\n",
      "156/156 [==============================] - 11s 72ms/step - loss: 1.0606 - acc: 0.5726 - val_loss: 0.9021 - val_acc: 0.5833\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.51894 to 0.58333, saving model to models\\Network-3XLVPH2095\\Network-3XLVPH2095.model\n",
      "Epoch 5/1000\n",
      "156/156 [==============================] - 11s 71ms/step - loss: 0.9801 - acc: 0.5943 - val_loss: 0.8827 - val_acc: 0.6061\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.58333 to 0.60606, saving model to models\\Network-3XLVPH2095\\Network-3XLVPH2095.model\n",
      "Epoch 6/1000\n",
      "156/156 [==============================] - 12s 75ms/step - loss: 0.9116 - acc: 0.6293 - val_loss: 0.7258 - val_acc: 0.6705\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.60606 to 0.67045, saving model to models\\Network-3XLVPH2095\\Network-3XLVPH2095.model\n",
      "Epoch 7/1000\n",
      "156/156 [==============================] - 11s 71ms/step - loss: 0.8287 - acc: 0.6458 - val_loss: 0.8566 - val_acc: 0.5871\n",
      "\n",
      "Epoch 00007: val_acc did not improve\n",
      "Epoch 8/1000\n",
      "156/156 [==============================] - 12s 74ms/step - loss: 0.7726 - acc: 0.6928 - val_loss: 0.7105 - val_acc: 0.7008\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.67045 to 0.70076, saving model to models\\Network-3XLVPH2095\\Network-3XLVPH2095.model\n",
      "Epoch 9/1000\n",
      "156/156 [==============================] - 12s 74ms/step - loss: 0.7046 - acc: 0.7294 - val_loss: 0.4982 - val_acc: 0.8220\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.70076 to 0.82197, saving model to models\\Network-3XLVPH2095\\Network-3XLVPH2095.model\n",
      "Epoch 10/1000\n",
      "156/156 [==============================] - 11s 71ms/step - loss: 0.6162 - acc: 0.7695 - val_loss: 0.5445 - val_acc: 0.8106\n",
      "\n",
      "Epoch 00010: val_acc did not improve\n",
      "Epoch 11/1000\n",
      "156/156 [==============================] - 11s 70ms/step - loss: 0.5605 - acc: 0.8045 - val_loss: 0.4950 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.82197 to 0.83333, saving model to models\\Network-3XLVPH2095\\Network-3XLVPH2095.model\n",
      "Epoch 12/1000\n",
      "156/156 [==============================] - 11s 70ms/step - loss: 0.5613 - acc: 0.7989 - val_loss: 0.4723 - val_acc: 0.8144\n",
      "\n",
      "Epoch 00012: val_acc did not improve\n",
      "Epoch 13/1000\n",
      "156/156 [==============================] - 11s 70ms/step - loss: 0.4220 - acc: 0.8403 - val_loss: 0.6125 - val_acc: 0.8144\n",
      "\n",
      "Epoch 00013: val_acc did not improve\n",
      "Epoch 14/1000\n",
      "156/156 [==============================] - 11s 71ms/step - loss: 0.4964 - acc: 0.8202 - val_loss: 0.7647 - val_acc: 0.7197\n",
      "\n",
      "Epoch 00014: val_acc did not improve\n",
      "Epoch 15/1000\n",
      "156/156 [==============================] - 11s 71ms/step - loss: 0.4908 - acc: 0.8392 - val_loss: 0.6455 - val_acc: 0.7652\n",
      "\n",
      "Epoch 00015: val_acc did not improve\n",
      "Epoch 16/1000\n",
      "156/156 [==============================] - 11s 70ms/step - loss: 0.3988 - acc: 0.8734 - val_loss: 0.6314 - val_acc: 0.8220\n",
      "\n",
      "Epoch 00016: val_acc did not improve\n",
      "Epoch 17/1000\n",
      "156/156 [==============================] - 11s 70ms/step - loss: 0.3506 - acc: 0.8870 - val_loss: 1.0761 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00017: val_acc did not improve\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 18/1000\n",
      "156/156 [==============================] - 11s 69ms/step - loss: 0.2691 - acc: 0.9140 - val_loss: 0.4793 - val_acc: 0.8561\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.83333 to 0.85606, saving model to models\\Network-3XLVPH2095\\Network-3XLVPH2095.model\n",
      "Epoch 19/1000\n",
      "156/156 [==============================] - 11s 70ms/step - loss: 0.2437 - acc: 0.9255 - val_loss: 0.6360 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00019: val_acc did not improve\n",
      "Epoch 20/1000\n",
      "156/156 [==============================] - 11s 70ms/step - loss: 0.2259 - acc: 0.9356 - val_loss: 0.4563 - val_acc: 0.8826\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.85606 to 0.88258, saving model to models\\Network-3XLVPH2095\\Network-3XLVPH2095.model\n",
      "Epoch 21/1000\n",
      "156/156 [==============================] - 11s 69ms/step - loss: 0.2324 - acc: 0.9298 - val_loss: 0.5500 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.88258 to 0.90530, saving model to models\\Network-3XLVPH2095\\Network-3XLVPH2095.model\n",
      "Epoch 22/1000\n",
      "156/156 [==============================] - 11s 70ms/step - loss: 0.1680 - acc: 0.9511 - val_loss: 0.6516 - val_acc: 0.8182\n",
      "\n",
      "Epoch 00022: val_acc did not improve\n",
      "Epoch 23/1000\n",
      "156/156 [==============================] - 11s 69ms/step - loss: 0.1512 - acc: 0.9535 - val_loss: 0.5485 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.90530 to 0.91667, saving model to models\\Network-3XLVPH2095\\Network-3XLVPH2095.model\n",
      "Epoch 24/1000\n",
      "156/156 [==============================] - 11s 71ms/step - loss: 0.1329 - acc: 0.9599 - val_loss: 0.5708 - val_acc: 0.9015\n",
      "\n",
      "Epoch 00024: val_acc did not improve\n",
      "Epoch 25/1000\n",
      "156/156 [==============================] - 11s 68ms/step - loss: 0.1571 - acc: 0.9463 - val_loss: 0.6470 - val_acc: 0.8902\n",
      "\n",
      "Epoch 00025: val_acc did not improve\n",
      "Epoch 26/1000\n",
      "156/156 [==============================] - 10s 66ms/step - loss: 0.1753 - acc: 0.9517 - val_loss: 0.5886 - val_acc: 0.9015\n",
      "\n",
      "Epoch 00026: val_acc did not improve\n",
      "Epoch 27/1000\n",
      "156/156 [==============================] - 11s 70ms/step - loss: 0.1886 - acc: 0.9471 - val_loss: 0.2861 - val_acc: 0.9280\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.91667 to 0.92803, saving model to models\\Network-3XLVPH2095\\Network-3XLVPH2095.model\n",
      "Epoch 28/1000\n",
      "156/156 [==============================] - 11s 70ms/step - loss: 0.1707 - acc: 0.9527 - val_loss: 0.8864 - val_acc: 0.8409\n",
      "\n",
      "Epoch 00028: val_acc did not improve\n",
      "Epoch 29/1000\n",
      "156/156 [==============================] - 11s 70ms/step - loss: 0.1967 - acc: 0.9367 - val_loss: 0.4550 - val_acc: 0.8977\n",
      "\n",
      "Epoch 00029: val_acc did not improve\n",
      "Epoch 30/1000\n",
      "156/156 [==============================] - 11s 70ms/step - loss: 0.1069 - acc: 0.9679 - val_loss: 0.7884 - val_acc: 0.8902\n",
      "\n",
      "Epoch 00030: val_acc did not improve\n",
      "Epoch 31/1000\n",
      "156/156 [==============================] - 11s 73ms/step - loss: 0.1431 - acc: 0.9551 - val_loss: 0.5928 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00031: val_acc did not improve\n",
      "Epoch 32/1000\n",
      "156/156 [==============================] - 11s 67ms/step - loss: 0.0936 - acc: 0.9712 - val_loss: 0.7262 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00032: val_acc did not improve\n",
      "Epoch 33/1000\n",
      "156/156 [==============================] - 11s 70ms/step - loss: 0.1885 - acc: 0.9407 - val_loss: 0.5155 - val_acc: 0.8902\n",
      "\n",
      "Epoch 00033: val_acc did not improve\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 34/1000\n",
      "156/156 [==============================] - 11s 69ms/step - loss: 0.1175 - acc: 0.9701 - val_loss: 0.3478 - val_acc: 0.9394\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.92803 to 0.93939, saving model to models\\Network-3XLVPH2095\\Network-3XLVPH2095.model\n",
      "Epoch 35/1000\n",
      "156/156 [==============================] - 11s 70ms/step - loss: 0.0930 - acc: 0.9768 - val_loss: 0.7209 - val_acc: 0.9015\n",
      "\n",
      "Epoch 00035: val_acc did not improve\n",
      "Epoch 36/1000\n",
      "156/156 [==============================] - 11s 71ms/step - loss: 0.1170 - acc: 0.9671 - val_loss: 0.5822 - val_acc: 0.9205\n",
      "\n",
      "Epoch 00036: val_acc did not improve\n",
      "Epoch 37/1000\n",
      "156/156 [==============================] - 11s 70ms/step - loss: 0.0950 - acc: 0.9760 - val_loss: 0.9350 - val_acc: 0.8826\n",
      "\n",
      "Epoch 00037: val_acc did not improve\n",
      "Epoch 38/1000\n",
      "156/156 [==============================] - 11s 69ms/step - loss: 0.0896 - acc: 0.9784 - val_loss: 0.9976 - val_acc: 0.8447\n",
      "\n",
      "Epoch 00038: val_acc did not improve\n",
      "Epoch 39/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 11s 70ms/step - loss: 0.0789 - acc: 0.9776 - val_loss: 0.5459 - val_acc: 0.9205\n",
      "\n",
      "Epoch 00039: val_acc did not improve\n",
      "Epoch 40/1000\n",
      "156/156 [==============================] - 11s 69ms/step - loss: 0.0840 - acc: 0.9752 - val_loss: 0.6716 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00040: val_acc did not improve\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 41/1000\n",
      "156/156 [==============================] - 11s 70ms/step - loss: 0.0552 - acc: 0.9856 - val_loss: 0.7017 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00041: val_acc did not improve\n",
      "Epoch 42/1000\n",
      "156/156 [==============================] - 11s 69ms/step - loss: 0.0896 - acc: 0.9776 - val_loss: 0.5434 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00042: val_acc did not improve\n",
      "Epoch 43/1000\n",
      "156/156 [==============================] - 11s 70ms/step - loss: 0.0852 - acc: 0.9757 - val_loss: 0.5878 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00043: val_acc did not improve\n",
      "Epoch 44/1000\n",
      "156/156 [==============================] - 11s 69ms/step - loss: 0.0407 - acc: 0.9896 - val_loss: 0.7176 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00044: val_acc did not improve\n",
      "Epoch 45/1000\n",
      "156/156 [==============================] - 11s 70ms/step - loss: 0.0617 - acc: 0.9824 - val_loss: 0.6819 - val_acc: 0.8977\n",
      "\n",
      "Epoch 00045: val_acc did not improve\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 46/1000\n",
      "156/156 [==============================] - 11s 70ms/step - loss: 0.0475 - acc: 0.9880 - val_loss: 0.6255 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00046: val_acc did not improve\n",
      "Epoch 47/1000\n",
      "156/156 [==============================] - 11s 70ms/step - loss: 0.0638 - acc: 0.9781 - val_loss: 0.5060 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00047: val_acc did not improve\n",
      "Epoch 48/1000\n",
      "156/156 [==============================] - 11s 70ms/step - loss: 0.0498 - acc: 0.9832 - val_loss: 0.6444 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00048: val_acc did not improve\n",
      "Epoch 49/1000\n",
      "156/156 [==============================] - 11s 70ms/step - loss: 0.0539 - acc: 0.9856 - val_loss: 0.4857 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00049: val_acc did not improve\n",
      "Epoch 00049: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fc932dbfd0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=validation_steps,\n",
    "        verbose=1, \n",
    "        callbacks=[check_point, \n",
    "                   early_stopping, \n",
    "                   tb_callback,\n",
    "                   reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовых данных: 98.16%\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(model_file_path)\n",
    "scores = model.evaluate_generator(test_generator, NeuClassificationSurfaceDefects.nb_test_samples // batch_size)\n",
    "acc = scores[1]*100\n",
    "print(\"Точность на тестовых данных: %.2f%%\" % (acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(model_dir, 'README.md'), \"w\") as fh:\n",
    "    print(\"Accuracy:  %.2f%%\\n\" % (acc), file=fh)\n",
    "    model.summary(print_fn=lambda x: fh.write(x + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('README.md', 'a') as fh:\n",
    "    print('| %s | %.2f%% | [models/%s/%s.model](https://github.com/Alkapov/Steel-Surface-NN/tree/master/models/%s/) |\\n' % (network_name, acc,  network_name, network_name, network_name), file=fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
